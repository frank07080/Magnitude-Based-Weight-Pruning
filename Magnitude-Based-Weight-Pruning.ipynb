{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Import Libraries\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd.variable import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets as dset\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import timeit\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Retrieve the Pretrained Model\n",
    "model = models.vgg11(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_model (\n",
      "  (vismodel): Sequential (\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU (inplace)\n",
      "    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU (inplace)\n",
      "    (5): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU (inplace)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU (inplace)\n",
      "    (10): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU (inplace)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU (inplace)\n",
      "    (15): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU (inplace)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU (inplace)\n",
      "    (20): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (fc): Linear (512 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### Define a new model, only work with half of VGG\n",
    "### Turn new model into gpu type, call in model_gpu\n",
    "import copy\n",
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "\n",
    "class new_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(new_model, self).__init__()\n",
    "        \n",
    "        self.vismodel = nn.Sequential(*list(model.children())[0])\n",
    "        self.fc = nn.Linear(512,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.vismodel(x)\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "new_model = new_model()\n",
    "print(new_model)\n",
    "model_gpu = copy.deepcopy(new_model).type(gpu_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.1119\n",
      "-0.7000\n",
      "-0.2815\n",
      "-0.6935\n",
      " 0.3994\n",
      " 2.0697\n",
      " 0.3658\n",
      " 0.3497\n",
      " 0.8487\n",
      " 0.1171\n",
      "[torch.cuda.FloatTensor of size 10 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Test the model out\n",
    "x_gpu = torch.randn(64, 3, 32, 32).type(gpu_dtype)\n",
    "x_var_gpu = Variable(x_gpu) # Construct a PyTorch Variable out of your input data\n",
    "ans = model_gpu(x_var_gpu)        # Feed it through the model!\n",
    "print(ans[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "### Retrieve dataset\n",
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "NUM_TRAIN = 10000\n",
    "NUM_VAL = 1000\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          sampler=ChunkSampler(NUM_TRAIN, 0))\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.963\n",
      "[2,  2000] loss: 2.031\n",
      "[3,  2000] loss: 1.742\n",
      "[4,  2000] loss: 1.510\n",
      "[5,  2000] loss: 1.364\n",
      "[6,  2000] loss: 1.219\n",
      "[7,  2000] loss: 1.121\n",
      "[8,  2000] loss: 1.018\n",
      "[9,  2000] loss: 0.914\n",
      "[10,  2000] loss: 0.874\n",
      "[11,  2000] loss: 0.813\n",
      "[12,  2000] loss: 0.725\n",
      "[13,  2000] loss: 0.746\n",
      "[14,  2000] loss: 0.656\n",
      "[15,  2000] loss: 0.586\n",
      "[16,  2000] loss: 0.634\n",
      "[17,  2000] loss: 0.592\n",
      "[18,  2000] loss: 0.519\n",
      "[19,  2000] loss: 0.519\n",
      "[20,  2000] loss: 0.481\n",
      "Finish Training\n"
     ]
    }
   ],
   "source": [
    "### Training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_gpu.parameters())\n",
    "running_loss = 0.0\n",
    "for epoch in range(20):\n",
    "    for i, data in enumerate(trainloader, 0): #i is a counter, start from 0, the tuple (i,data) \n",
    "                                          #is produced\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs_gpu = inputs.type(gpu_dtype)\n",
    "        labels_gpu = labels.type(gpu_dtype).long()\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs_gpu), Variable(labels_gpu)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model_gpu(inputs) # Forward -> score\n",
    "        loss = criterion(outputs, labels) # Forward -> loss\n",
    "        loss.backward() # Backward generate gradients\n",
    "        optimizer.step() # Update Parameters\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print(\"Finish Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 61 %\n"
     ]
    }
   ],
   "source": [
    "### Compute Accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    images = images.type(gpu_dtype)\n",
    "    labels = labels.type(gpu_dtype).long()\n",
    "    outputs = model_gpu(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1) # return (每一横行最大的那个数，这个数所在的index)\n",
    "    total += labels.size(0) #will be added up to 10,000, 每次有4个 - batch size\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU (inplace)\n",
      "MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU (inplace)\n",
      "MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU (inplace)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU (inplace)\n",
      "MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU (inplace)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU (inplace)\n",
      "MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU (inplace)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU (inplace)\n",
      "MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "### Pruning Conv Layer\n",
    "index_dict4d = dict([(\"conv1\", []),(\"conv2\", []),(\"conv3\", []),(\"conv4\", []),(\"conv5\", []),(\"conv6\", []),(\"conv7\", []),(\"conv8\", [])])\n",
    "index_dict1d = dict([(\"conv1\", []),(\"conv2\", []),(\"conv3\", []),(\"conv4\", []),(\"conv5\", []),(\"conv6\", []),(\"conv7\", []),(\"conv8\", [])])\n",
    "conv_counter = 0\n",
    "\n",
    "# Freeze the parameters that is less than a threshold, Say -0.5\n",
    "# When I say freeze up, I mean set the weight to 0\n",
    "for child in model_gpu.children():\n",
    "    for children_of_child in child.children(): # Going thru all layers of the network\n",
    "        print(children_of_child)\n",
    "        if \"Conv2d\" in str(children_of_child): #check if it is a conv layer\n",
    "            conv_counter += 1\n",
    "            #print(\"total parameters:\",len(list(children_of_child.parameters())))\n",
    "            for param in children_of_child.parameters():\n",
    "                #print(type(param.data[0,0,0,0]))\n",
    "                if len(param.data.size()) == 4:\n",
    "                    #Loop through all the entries\n",
    "                    for i in range(param.data.size()[0]):\n",
    "                        for j in range(param.data.size()[1]):\n",
    "                            for k in range(param.data.size()[2]):\n",
    "                                for l in range(param.data.size()[3]):\n",
    "                                    if param.data[i,j,k,l] < -0.5:\n",
    "                                        param.data[i,j,k,l] = 0\n",
    "                                        index_name = \"conv\" + str(conv_counter)\n",
    "                                        index_dict4d[index_name].append([i,j,k,l])\n",
    "                else:\n",
    "                    for i in range(param.data.size()[0]):\n",
    "                        if param.data[i] < -0.5:\n",
    "                            param.data[i] = 0\n",
    "                            index_name = \"conv\" + str(conv_counter)\n",
    "                            index_dict1d[index_name].append(i)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 7, 10, 14, 15, 17, 19, 21, 22, 23, 26, 28, 29, 30, 31, 32, 38, 41, 43, 50, 51, 52, 57, 58, 60, 63]\n",
      "\n",
      "(0 ,0 ,.,.) = \n",
      "  0.1628  0.0532 -0.2291\n",
      "  0.0334  0.4052 -0.4388\n",
      " -0.2271  0.3733 -0.1803\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "  0.2702 -0.0601  0.0000\n",
      "  0.3376  0.4988  0.0000\n",
      "  0.0164  0.5087 -0.3284\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      "  0.1215 -0.0277 -0.3225\n",
      "  0.0875  0.3706 -0.3914\n",
      " -0.0539  0.4169 -0.0967\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -0.2983 -0.2527  0.5494\n",
      "  0.0000 -0.3279  0.7624\n",
      " -0.3069 -0.0826  0.6425\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      "  0.0000 -0.3998  0.6207\n",
      "  0.0000 -0.3210  1.0808\n",
      " -0.4434 -0.0339  0.8969\n",
      "\n",
      "(1 ,2 ,.,.) = \n",
      "  0.0251 -0.2610  0.1148\n",
      " -0.1314 -0.2159  0.3815\n",
      " -0.0313 -0.0154  0.3842\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      "  0.0814 -0.0218  0.2336\n",
      "  0.1044  0.1847 -0.0872\n",
      " -0.4612  0.0197 -0.0651\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      " -0.0434 -0.3602 -0.1910\n",
      "  0.2864  0.2199 -0.3160\n",
      " -0.2144  0.2654 -0.0338\n",
      "\n",
      "(2 ,2 ,.,.) = \n",
      "  0.0228 -0.1605 -0.0345\n",
      "  0.2336  0.2143 -0.1375\n",
      " -0.1072  0.2294  0.0480\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(61,0 ,.,.) = \n",
      "  0.3634  0.5034  0.2240\n",
      "  0.0000  0.0000 -0.4743\n",
      "  0.2981  0.2963  0.0389\n",
      "\n",
      "(61,1 ,.,.) = \n",
      "  0.6348  0.7893  0.4192\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.4838  0.4716  0.1393\n",
      "\n",
      "(61,2 ,.,.) = \n",
      "  0.3628  0.4139  0.0768\n",
      " -0.4535  0.0000 -0.2401\n",
      "  0.4592  0.4699  0.1293\n",
      "     ⋮ \n",
      "\n",
      "(62,0 ,.,.) = \n",
      "  0.1438  0.3126  0.1062\n",
      "  0.3146  0.4541  0.1320\n",
      "  0.1093  0.1443 -0.1314\n",
      "\n",
      "(62,1 ,.,.) = \n",
      " -0.2564 -0.4469 -0.1599\n",
      "  0.0000  0.0000 -0.3839\n",
      " -0.1752 -0.3704 -0.1812\n",
      "\n",
      "(62,2 ,.,.) = \n",
      "  0.2165  0.2275  0.2734\n",
      "  0.2880  0.2686  0.3011\n",
      "  0.3558  0.2807  0.2634\n",
      "     ⋮ \n",
      "\n",
      "(63,0 ,.,.) = \n",
      "  0.1509  0.1006  0.1294\n",
      " -0.0706 -0.0633  0.0858\n",
      " -0.1067 -0.0601  0.1159\n",
      "\n",
      "(63,1 ,.,.) = \n",
      " -0.0247 -0.1127 -0.0493\n",
      " -0.1838 -0.2157 -0.0789\n",
      " -0.1708 -0.1463  0.0042\n",
      "\n",
      "(63,2 ,.,.) = \n",
      "  0.0531  0.0436  0.0277\n",
      " -0.0047 -0.0580  0.0491\n",
      " -0.0303 -0.0049  0.0784\n",
      "[torch.cuda.FloatTensor of size 64x3x3x3 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(index_dict1d[\"conv1\"])\n",
    "#### Visualize a set of pruned parameters\n",
    "for child in model_gpu.children():\n",
    "    for children_of_child in child.children(): # Going thru all layers of the network\n",
    "        for param in children_of_child.parameters():\n",
    "            if len(param.data.size()) == 4:\n",
    "                #Loop through all the entries\n",
    "                print(param.data)\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 15 %\n"
     ]
    }
   ],
   "source": [
    "### Check accuracy after pruning without retraining\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    images = images.type(gpu_dtype)\n",
    "    labels = labels.type(gpu_dtype).long()\n",
    "    outputs = model_gpu(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1) # return (每一横行最大的那个数，这个数所在的index)\n",
    "    total += labels.size(0) #will be added up to 10,000, 每次有4个 - batch size\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child  0 of child 0  requires gradient\n",
      "child  3 of child 0  requires gradient\n",
      "child  6 of child 0  requires gradient\n",
      "child  8 of child 0  requires gradient\n",
      "child  11 of child 0  requires gradient\n",
      "child  13 of child 0  requires gradient\n",
      "child  16 of child 0  requires gradient\n",
      "child  18 of child 0  requires gradient\n"
     ]
    }
   ],
   "source": [
    "### Add up hook to gradient in order to avoid updating certain weights\n",
    "def my_hook4d1(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict4d[\"conv1\"])):\n",
    "        a,b,c,d = index_dict4d[\"conv1\"][i]\n",
    "        grad_clone[a,b,c,d] = 0\n",
    "    return grad_clone\n",
    "\n",
    "def my_hook4d2(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict4d[\"conv2\"])):\n",
    "        a,b,c,d = index_dict4d[\"conv2\"][i]\n",
    "        grad_clone[a,b,c,d] = 0\n",
    "    return grad_clone\n",
    "\n",
    "def my_hook4d3(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict4d[\"conv3\"])):\n",
    "        a,b,c,d = index_dict4d[\"conv3\"][i]\n",
    "        grad_clone[a,b,c,d] = 0\n",
    "    return grad_clone\n",
    "\n",
    "def my_hook4d4(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict4d[\"conv4\"])):\n",
    "        a,b,c,d = index_dict4d[\"conv4\"][i]\n",
    "        grad_clone[a,b,c,d] = 0\n",
    "    return grad_clone\n",
    "\n",
    "def my_hook4d5(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict4d[\"conv5\"])):\n",
    "        a,b,c,d = index_dict4d[\"conv5\"][i]\n",
    "        grad_clone[a,b,c,d] = 0\n",
    "    return grad_clone\n",
    "\n",
    "def my_hook4d6(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict4d[\"conv6\"])):\n",
    "        a,b,c,d = index_dict4d[\"conv6\"][i]\n",
    "        grad_clone[a,b,c,d] = 0\n",
    "    return grad_clone\n",
    "\n",
    "def my_hook4d7(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict4d[\"conv7\"])):\n",
    "        a,b,c,d = index_dict4d[\"conv7\"][i]\n",
    "        grad_clone[a,b,c,d] = 0\n",
    "    return grad_clone\n",
    "\n",
    "def my_hook4d8(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict4d[\"conv8\"])):\n",
    "        a,b,c,d = index_dict4d[\"conv8\"][i]\n",
    "        grad_clone[a,b,c,d] = 0\n",
    "    return grad_clone\n",
    "\n",
    "hook_dict4d = dict([(\"hook1\",my_hook4d1),(\"hook2\",my_hook4d2),(\"hook3\",my_hook4d3),(\"hook4\",my_hook4d4),(\"hook5\",my_hook4d5),(\"hook6\",my_hook4d6),(\"hook7\",my_hook4d7),(\"hook8\",my_hook4d8)])\n",
    "\n",
    "def my_hook1d1(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict1d[\"conv1\"])):\n",
    "        a = index_dict1d[\"conv1\"][i]\n",
    "        grad_clone[a] = 0\n",
    "    return grad_clone\n",
    "\n",
    "def my_hook1d2(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict1d[\"conv2\"])):\n",
    "        a = index_dict1d[\"conv2\"][i]\n",
    "        grad_clone[a] = 0\n",
    "    return grad_clone\n",
    "\n",
    "def my_hook1d3(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict1d[\"conv3\"])):\n",
    "        a = index_dict1d[\"conv3\"][i]\n",
    "        grad_clone[a] = 0\n",
    "    return grad_clone\n",
    "\n",
    "def my_hook1d4(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict1d[\"conv4\"])):\n",
    "        a = index_dict1d[\"conv4\"][i]\n",
    "        grad_clone[a] = 0\n",
    "    return grad_clone\n",
    "\n",
    "def my_hook1d5(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict1d[\"conv5\"])):\n",
    "        a = index_dict1d[\"conv5\"][i]\n",
    "        grad_clone[a] = 0\n",
    "    return grad_clone\n",
    "\n",
    "def my_hook1d6(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict1d[\"conv6\"])):\n",
    "        a = index_dict1d[\"conv6\"][i]\n",
    "        grad_clone[a] = 0\n",
    "    return grad_clone\n",
    "\n",
    "def my_hook1d7(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict1d[\"conv7\"])):\n",
    "        a = index_dict1d[\"conv7\"][i]\n",
    "        grad_clone[a] = 0\n",
    "    return grad_clone\n",
    "\n",
    "def my_hook1d8(grad):\n",
    "    grad_clone = grad.clone()\n",
    "    for i in range(len(index_dict1d[\"conv8\"])):\n",
    "        a = index_dict1d[\"conv8\"][i]\n",
    "        grad_clone[a] = 0\n",
    "    return grad_clone\n",
    "\n",
    "hook_dict1d = dict([(\"hook1\",my_hook1d1),(\"hook2\",my_hook1d2),(\"hook3\",my_hook1d3),(\"hook4\",my_hook1d4),(\"hook5\",my_hook1d5),(\"hook6\",my_hook1d6),(\"hook7\",my_hook1d7),(\"hook8\",my_hook1d8)])\n",
    "\n",
    "conv_counter = 0\n",
    "child_counter = 0\n",
    "for child in model_gpu.children():\n",
    "    children_of_child_counter = 0\n",
    "    for children_of_child in child.children(): # Going thru all layers of the network\n",
    "        if \"Conv2d\" in str(children_of_child): #check if it is a conv layer\n",
    "            conv_counter += 1\n",
    "            for param in children_of_child.parameters():\n",
    "                if len(param.data.size()) == 4:\n",
    "                    hook_name = \"hook\" + str(conv_counter)\n",
    "                    param.register_hook(hook_dict4d[hook_name])\n",
    "                    print('child ', children_of_child_counter, 'of child',child_counter,' requires gradient')\n",
    "                else:\n",
    "                    hook_name = \"hook\" + str(conv_counter)\n",
    "                    param.register_hook(hook_dict1d[hook_name])\n",
    "        else:\n",
    "            for param in children_of_child.parameters():\n",
    "                param.requires_grad = False\n",
    "        children_of_child_counter += 1\n",
    "    child_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.825\n",
      "[2,  2000] loss: 1.723\n",
      "[3,  2000] loss: 1.305\n",
      "[4,  2000] loss: 1.047\n",
      "[5,  2000] loss: 0.860\n",
      "Finish Training\n"
     ]
    }
   ],
   "source": [
    "### Retraining\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_gpu.parameters())\n",
    "running_loss = 0.0\n",
    "for epoch in range(5):\n",
    "    for i, data in enumerate(trainloader, 0): #i is a counter, start from 0, the tuple (i,data) \n",
    "                                          #is produced\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs_gpu = inputs.type(gpu_dtype)\n",
    "        labels_gpu = labels.type(gpu_dtype).long()\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs_gpu), Variable(labels_gpu)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model_gpu(inputs) # Forward -> score\n",
    "        loss = criterion(outputs, labels) # Forward -> loss\n",
    "        loss.backward() # Backward generate gradients\n",
    "        optimizer.step() # Update Parameters\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print(\"Finish Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,0 ,.,.) = \n",
      "  0.1815  0.0097 -0.3997\n",
      " -0.0021  0.3798 -0.6989\n",
      " -0.2638  0.4159 -0.3177\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "  0.2437 -0.1695  0.0000\n",
      "  0.2635  0.4127  0.0000\n",
      " -0.0465  0.4961 -0.5362\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      "  0.1580 -0.0457 -0.4509\n",
      "  0.0729  0.3713 -0.5718\n",
      " -0.0717  0.4613 -0.1932\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -0.4471 -0.3161  0.5461\n",
      "  0.0000 -0.4608  0.7493\n",
      " -0.4650 -0.1266  0.6495\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      "  0.0000 -0.5272  0.5692\n",
      "  0.0000 -0.5083  1.0261\n",
      " -0.6355 -0.1450  0.8409\n",
      "\n",
      "(1 ,2 ,.,.) = \n",
      " -0.0908 -0.3115  0.1389\n",
      " -0.3261 -0.3288  0.3939\n",
      " -0.1672 -0.0851  0.3785\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      "  0.1070 -0.0997  0.1548\n",
      "  0.1702  0.2074 -0.1850\n",
      " -0.4211  0.0529 -0.1714\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      " -0.0324 -0.4525 -0.2831\n",
      "  0.3735  0.2597 -0.4072\n",
      " -0.1380  0.3340 -0.1186\n",
      "\n",
      "(2 ,2 ,.,.) = \n",
      "  0.0306 -0.2275 -0.1110\n",
      "  0.2961  0.2516 -0.2088\n",
      " -0.0426  0.2926 -0.0051\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(61,0 ,.,.) = \n",
      "  0.1343  0.2353  0.0022\n",
      "  0.0000  0.0000 -0.8001\n",
      " -0.0093 -0.0114 -0.1382\n",
      "\n",
      "(61,1 ,.,.) = \n",
      "  0.4346  0.5454  0.2508\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.2339  0.2168  0.0374\n",
      "\n",
      "(61,2 ,.,.) = \n",
      "  0.1593  0.1688 -0.0463\n",
      " -0.7499  0.0000 -0.4500\n",
      "  0.2728  0.2585  0.0805\n",
      "     ⋮ \n",
      "\n",
      "(62,0 ,.,.) = \n",
      "  0.0754  0.2241 -0.0020\n",
      "  0.2377  0.3490  0.0543\n",
      "  0.0261  0.0265 -0.2381\n",
      "\n",
      "(62,1 ,.,.) = \n",
      " -0.3461 -0.5418 -0.2434\n",
      "  0.0000  0.0000 -0.4437\n",
      " -0.2703 -0.4721 -0.2508\n",
      "\n",
      "(62,2 ,.,.) = \n",
      "  0.1568  0.1695  0.2320\n",
      "  0.2168  0.1983  0.2838\n",
      "  0.2836  0.2098  0.2195\n",
      "     ⋮ \n",
      "\n",
      "(63,0 ,.,.) = \n",
      "  0.1344  0.0493  0.0483\n",
      " -0.0241 -0.0446  0.0301\n",
      " -0.0126  0.0032  0.0905\n",
      "\n",
      "(63,1 ,.,.) = \n",
      " -0.0003 -0.1082 -0.0533\n",
      " -0.1086 -0.1589 -0.0795\n",
      " -0.0503 -0.0596  0.0264\n",
      "\n",
      "(63,2 ,.,.) = \n",
      "  0.0877  0.0675  0.0463\n",
      "  0.0765  0.0060  0.0565\n",
      "  0.0835  0.0782  0.0969\n",
      "[torch.cuda.FloatTensor of size 64x3x3x3 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Checking if pruned parameters are set to be 0\n",
    "for child in model_gpu.children():\n",
    "    for children_of_child in child.children(): # Going thru all layers of the network\n",
    "        for param in children_of_child.parameters():\n",
    "            if len(param.data.size()) == 4:\n",
    "                #Loop through all the entries\n",
    "                print(param.data)\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 59 %\n"
     ]
    }
   ],
   "source": [
    "### Check accuracy after pruning with 5 epochs retraining\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    images = images.type(gpu_dtype)\n",
    "    labels = labels.type(gpu_dtype).long()\n",
    "    outputs = model_gpu(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1) # return (每一横行最大的那个数，这个数所在的index)\n",
    "    total += labels.size(0) #will be added up to 10,000, 每次有4个 - batch size\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we pruned a total of 9065 weights\n"
     ]
    }
   ],
   "source": [
    "pruned_counter = 0\n",
    "for child in model_gpu.children():\n",
    "    for children_of_child in child.children(): # Going thru all layers of the network\n",
    "        if \"Conv2d\" in str(children_of_child): #check if it is a conv layer\n",
    "            for param in children_of_child.parameters():\n",
    "                if len(param.data.size()) == 4:\n",
    "                    #Loop through all the entries\n",
    "                    for i in range(param.data.size()[0]):\n",
    "                        for j in range(param.data.size()[1]):\n",
    "                            for k in range(param.data.size()[2]):\n",
    "                                for l in range(param.data.size()[3]):\n",
    "                                    if param.data[i,j,k,l] == 0:\n",
    "                                        pruned_counter += 1\n",
    "                else:\n",
    "                    for i in range(param.data.size()[0]):\n",
    "                        if param.data[i] == 0:\n",
    "                            pruned_counter += 1\n",
    "\n",
    "print(\"we pruned a total of\",pruned_counter,\"weights\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
